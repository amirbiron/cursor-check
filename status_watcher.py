import os
import time
import json
import re
from typing import Callable, Dict, Any, List, Optional
import requests
import xml.etree.ElementTree as ET


# ---- ×”×’×“×¨×•×ª ×Ö¾ENV (××¤×©×¨ ×’× ××”×§×•×‘×¥ ×”×§×•×¨×) ----
DEFAULT_FEED_URL = os.getenv("STATUS_FEED_URL", "").strip()  # ×œ×“×•×’××”: https://status.cursor.com/history.atom ××• .rss
POLL_SEC = int(os.getenv("STATUS_POLL_SEC", "180"))          # ×›×œ ×›××” ×©× ×™×•×ª ×œ×‘×“×•×§ ×¤×™×“ (×“×™×¤×•×œ×˜: 3 ×“×§')
STATE_PATH = os.getenv("STATUS_STATE_PATH", "/tmp/status_feed_state.json")


def _norm_text(s: Optional[str]) -> str:
    return (s or "").strip()


def _get_text(elem: Optional[ET.Element]) -> str:
    return _norm_text(elem.text if elem is not None else "")


def _parse_atom(root: ET.Element) -> List[Dict[str, Any]]:
    ns = {"a": "http://www.w3.org/2005/Atom"}
    items = []
    for entry in root.findall(".//a:entry", ns):
        entry_id = _get_text(entry.find("a:id", ns))
        title = _get_text(entry.find("a:title", ns))
        updated = _get_text(entry.find("a:updated", ns)) or _get_text(entry.find("a:published", ns))
        link = ""
        link_el = entry.find("a:link", ns)
        if link_el is not None:
            link = link_el.get("href", "")
        summary = _get_text(entry.find("a:summary", ns))
        # ×œ×¤×¢××™× ×™×© ×ª×•×›×Ÿ ×•×œ× ×¡×™×›×•×
        content_el = entry.find("a:content", ns)
        content = _get_text(content_el) if content_el is not None else ""
        items.append(
            {
                "id": entry_id or f"{title}|{updated}",
                "title": title,
                "updated": updated,
                "link": link,
                "summary": summary or content,
            }
        )
    return items


def _parse_rss(root: ET.Element) -> List[Dict[str, Any]]:
    items = []
    for item in root.findall(".//item"):
        guid_el = item.find("guid")
        guid = _get_text(guid_el)
        title = _get_text(item.find("title"))
        pub = _get_text(item.find("pubDate")) or _get_text(item.find("date"))
        link = _get_text(item.find("link"))
        desc = _get_text(item.find("description"))
        items.append(
            {
                "id": guid or f"{title}|{pub}",
                "title": title,
                "updated": pub,
                "link": link,
                "summary": desc,
            }
        )
    return items


def _load_state(path: str) -> Dict[str, Any]:
    try:
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception:
        return {"last_ids": []}  # × ×©××•×¨ ×¢×“ 50 ××—×¨×•× ×™×


def _save_state(path: str, state: Dict[str, Any]) -> None:
    try:
        with open(path, "w", encoding="utf-8") as f:
            json.dump(state, f)
    except Exception:
        pass


def _classify(title: str, body: str) -> str:
    """×× ×¡×” ×œ×©×™× ××™×™×§×•×Ÿ ×œ×¤×™ ××™×œ×™× × ×¤×•×¦×•×ª."""
    t = f"{title} {body}".lower()
    if re.search(r"\b(resolved|fixed|restored|monitoring)\b", t):
        return "âœ… Resolved"
    if re.search(r"\b(investigating|degraded|degradation|partial outage|incident)\b", t):
        return "ğŸš¨ Incident"
    if re.search(r"\b(identified|mitigating|recovering)\b", t):
        return "ğŸ› ï¸ Mitigating"
    return "ğŸ”” Update"


def _format_msg(item: Dict[str, Any]) -> str:
    title = item.get("title") or ""
    when = item.get("updated") or ""
    link = item.get("link") or ""
    summary = item.get("summary") or ""
    label = _classify(title, summary)
    # ×—×™×ª×•×š ×ª×§×¦×™×¨ ×œ××•×‘×™×™×œ
    short = summary.strip().replace("\n", " ")
    if len(short) > 280:
        short = short[:277] + "..."
    parts = [
        f"{label}: {title}",
        f"ğŸ•’ {when}" if when else "",
        f"ğŸ”— {link}" if link else "",
        f"â€” {short}" if short else "",
    ]
    return "\n".join([p for p in parts if p])


def _fetch_feed(feed_url: str) -> List[Dict[str, Any]]:
    r = requests.get(feed_url, timeout=12)
    r.raise_for_status()
    # × × ×¡×” ×œ×–×”×•×ª ××˜×•×/â€RSS ×œ×¤×™ root tag
    root = ET.fromstring(r.text)
    tag = root.tag.lower()
    if "feed" in tag:   # atom
        return _parse_atom(root)
    return _parse_rss(root)  # rss


def watch_once(feed_url: str, state: Dict[str, Any], on_event: Callable[[str], None]) -> Dict[str, Any]:
    last_ids: List[str] = list(state.get("last_ids", []))
    items = _fetch_feed(feed_url)
    # newest first ×× ××¤×©×¨ (×œ×¤×™ ×¡×“×¨ ×”×•×¤×¢×”)
    new_msgs = []
    for it in items:
        _id = it.get("id") or ""
        if not _id:
            continue
        if _id in last_ids:
            continue
        new_msgs.append(_format_msg(it))
        last_ids.append(_id)

    # ×’×‘×•×œ ×œ×¨×©×™××ª ×”Ö¾ids
    if len(last_ids) > 50:
        last_ids = last_ids[-50:]

    # ×©×œ×™×—×ª ×”×•×“×¢×•×ª ×‘×¡×“×¨ ××”×™×©×Ÿ ×œ×—×“×© ×›×“×™ ×œ× ×œ×‘×œ×’×Ÿ ×›×¨×•× ×•×œ×•×’×™×”
    for msg in reversed(new_msgs):
        try:
            on_event(msg)
        except Exception:
            pass

    state["last_ids"] = last_ids
    return state


def start_status_watcher(
    feed_url: Optional[str],
    poll_sec: Optional[int],
    state_path: Optional[str],
    send_fn: Callable[[str], None],
) -> None:
    """
    ××¨×™×¥ ×œ×•×œ××” ×‘×—×•×˜ × ×¤×¨×“: ××•×©×š ×¤×™×“ ×¡×˜×˜×•×¡ ×›×œ poll_sec ×©× ×™×•×ª, ×©×•×œ×— ×¢×“×›×•× ×™× ×—×“×©×™×.
    """
    url = (feed_url or DEFAULT_FEED_URL).strip()
    if not url:
        print("â„¹ï¸ STATUS_FEED_URL not set â€“ skipping status watcher", flush=True)
        return

    interval = int(poll_sec or POLL_SEC)
    path = state_path or STATE_PATH

    def _run():
        st = _load_state(path)
        print(f"ğŸ”­ status watcher started (feed={url}, every {interval}s)", flush=True)
        while True:
            try:
                st = watch_once(url, st, send_fn)
                _save_state(path, st)
            except Exception as e:
                print(f"â— status watcher error: {e}", flush=True)
            time.sleep(interval)

    import threading as _t

    _t.Thread(target=_run, daemon=True).start()
